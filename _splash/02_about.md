---
title: "about"
bg: sanfrancisco
color: white
fa-icon: 
---

# About the Project

The Humanities + Design research lab at Stanford has developed [Palladio](http://hdlab.stanford.edu/palladio), [Breve](http://hdlab.stanford.edu/palladio), and a number of other prototype visualizations to help scholars explore and manipulate multidimensional historical data. Palladio fulfilled a need to look at data in familiar ways; to investigate it closely and carefully in the form of maps, timelines, graphs and tables. The responsive, interlinked, and interactive visualizations encourage a reflective reading or what we call thinking through data.

In the humanities, the material we work with and the questions we ask of it are, for the most part, not well suited to predictive modeling. The computing practices that help us navigate and parse data at machine scale like data mining, pattern recognition, and machine learning, are not adept at handling the small scale, idiosyncratic nature of historical data. So while we depend upon machine scale computing to help us wade through the sea of data and discover what is relevant, we also need human scale tools that support critical inquiry into the data themselves.

<strong>Gathering sources.</strong> One frustration we encountered was gathering and managing the data before we plugged it into Palladio. Historical data are messy and incomplete in unpredictable ways. What if we could make use of authorities, gazetteers and knowledge bases like [VIAF](https://viaf.org/), the [Library of Congress](http://authorities.loc.gov/), [Geoname](http://geonames.org) [Wikidata](https://www.wikidata.org/) and the [Getty Vocabularies](https://www.getty.edu/research/tools/vocabularies/) not only to identify the people, places and objects of our research but also to draw in related information about those entities. So when we type "Paris" the word will not only be imbued with the meaning is has for us individually, it can be identified as a place that exists in space and time with already defined relationships to other places, people, and objects in our data set.

<strong>Building an argument.</strong> The next greatest frustration was the inability to create and edit data directly in Palladio. To properly support the creative and reflective process of thinking through data we need to enable reading, writing and editing of those data. The specific actions we have identified are: creating, deleting, editing, disambiguation, annotation, grouping, and categorization. Then export. But we do not want to just export the tabular data. We want to be able to capture both the data and the model or schema so that the data created will have context within the scholarly community and the larger linked data ecosystem.

Digital libraries and research institutions are building a rich web of linked culture heritage data that is already changing the kinds of questions we can ask of the past. Gathering information from far and wide opens new doors and presents new challenges. The context that we take for granted in the discovery process will often be hidden in online search. Queries will need to be both more specific and more complex to help find exacty what we need from all the information that is available. With Fibra, the idea is to give over some of that data modeling work back to scholars. Then publish that new knowledge to the community where it can be cited, re-used and built upon by others.

